{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T11:55:05.724Z",
    "slug": "cjharmath-postgres-performance",
    "source_url": "https://github.com/CJHarmath/claude-agents-skills/tree/main/skills/postgres-performance",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "a9d3b1a51f621c8423720a8a95bda5c1ded938920d247baee3b504183e0ab608",
    "tree_hash": "99b7abbf87aba255b1b1e2a4c968d9a5cffe83b8b62854d4f5485dcc92454566"
  },
  "skill": {
    "name": "postgres-performance",
    "description": "High-performance PostgreSQL patterns. Use when optimizing queries, designing for scale, or debugging performance issues.",
    "summary": "High-performance PostgreSQL patterns. Use when optimizing queries, designing for scale, or debugging...",
    "icon": "üêò",
    "version": "1.0.0",
    "author": "CJHarmath",
    "license": "MIT",
    "category": "data",
    "tags": [
      "postgresql",
      "database",
      "performance",
      "optimization",
      "sql"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing only markdown documentation with SQL and Python code examples. No executable code, scripts, network calls, file system access, or external commands detected.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 441,
    "audit_model": "claude",
    "audited_at": "2026-01-10T11:55:05.724Z"
  },
  "content": {
    "user_title": "Optimize PostgreSQL Queries and Database Performance",
    "value_statement": "Slow database queries compound as data grows. This skill provides proven patterns for query optimization, indexing strategies, and scaling techniques that keep applications fast at any scale.",
    "seo_keywords": [
      "PostgreSQL performance",
      "database optimization",
      "query tuning",
      "index optimization",
      "PostgreSQL indexing",
      "cursor pagination",
      "connection pooling",
      "database scaling",
      "PostgreSQL",
      "Claude Code"
    ],
    "actual_capabilities": [
      "Identify slow queries using pg_stat_statements and EXPLAIN ANALYZE",
      "Create covering indexes for index-only scans and faster queries",
      "Implement cursor-based pagination instead of slow OFFSET pagination",
      "Optimize batch processing with SKIP LOCKED to avoid locks",
      "Configure connection pooling for serverless and long-running applications",
      "Monitor table bloat, cache hit ratios, and long-running queries"
    ],
    "limitations": [
      "Does not execute queries or modify database schema automatically",
      "Requires user to adapt SQL patterns to their specific schema",
      "Does not replace proper database monitoring and observability tools",
      "Performance gains depend on database infrastructure and configuration"
    ],
    "use_cases": [
      {
        "target_user": "Backend developers",
        "title": "Debug and Fix Slow Queries",
        "description": "Use EXPLAIN ANALYZE and pg_stat_statements to identify bottlenecks and apply indexing solutions."
      },
      {
        "target_user": "Database engineers",
        "title": "Design Scalable Schema Patterns",
        "description": "Implement partitioning, denormalization, and read replicas for high-throughput applications."
      },
      {
        "target_user": "DevOps engineers",
        "title": "Optimize Database Infrastructure",
        "description": "Configure connection pools, caching layers, and monitoring for production database health."
      }
    ],
    "prompt_templates": [
      {
        "title": "Analyze Slow Query",
        "scenario": "Find why a query is slow",
        "prompt": "My PostgreSQL query is slow. Help me analyze it using pg_stat_statements and EXPLAIN ANALYZE. Show me how to identify the bottleneck and fix it."
      },
      {
        "title": "Improve Pagination",
        "scenario": "Replace slow OFFSET pagination",
        "prompt": "My application uses OFFSET pagination and it is getting slow at high page numbers. Show me how to implement cursor-based pagination in PostgreSQL and SQLAlchemy."
      },
      {
        "title": "Optimize Batch Jobs",
        "scenario": "Process large datasets efficiently",
        "prompt": "I need to process millions of records in PostgreSQL without causing locks or timeouts. Show me the SKIP LOCKED pattern and batch processing approach."
      },
      {
        "title": "Scale Read Operations",
        "scenario": "Set up read replicas",
        "prompt": "My PostgreSQL database has heavy read load. Show me how to implement read replicas and route reads to replicas while writes go to the primary."
      }
    ],
    "output_examples": [
      {
        "input": "My SELECT queries are slow on a table with 10 million rows.",
        "output": [
          "1. Enable pg_stat_statements to identify the slowest queries",
          "2. Run EXPLAIN ANALYZE to check for sequential scans on large tables",
          "3. Add appropriate indexes matching your WHERE and ORDER BY clauses",
          "4. Use covering indexes (INCLUDE) to avoid heap fetches",
          "5. Consider partitioning the table if it exceeds 10M rows",
          "6. Add Redis caching for frequently accessed data"
        ]
      }
    ],
    "best_practices": [
      "Always verify query plans with EXPLAIN ANALYZE after adding indexes",
      "Use cursor-based pagination instead of OFFSET for large datasets",
      "Monitor cache hit ratios and index usage to identify optimization opportunities"
    ],
    "anti_patterns": [
      "Using OFFSET pagination on tables with millions of rows",
      "Creating indexes without analyzing actual query patterns",
      "Running large updates or deletes without batch processing"
    ],
    "faq": [
      {
        "question": "Which PostgreSQL versions are supported?",
        "answer": "Patterns work on PostgreSQL 13 and later. Some features like SKIP LOCKED require PostgreSQL 9.5+."
      },
      {
        "question": "What table sizes benefit from these optimizations?",
        "answer": "Optimizations provide the most benefit for tables with over 100,000 rows. Pagination and indexing matter most at scale."
      },
      {
        "question": "How does this skill integrate with existing tools?",
        "answer": "The skill provides SQL patterns and Python code examples compatible with SQLAlchemy, asyncpg, and psycopg2."
      },
      {
        "question": "Is my data safe when using these patterns?",
        "answer": "This skill only provides patterns. All queries run in your database. No data is sent anywhere or accessed by the skill."
      },
      {
        "question": "Why are my queries still slow after adding indexes?",
        "answer": "Check if statistics are updated with ANALYZE. Verify the index matches query patterns. Consider if covering indexes are needed."
      },
      {
        "question": "How is this different from pgBadger or pg_stat_statements?",
        "answer": "This skill provides optimization patterns. Those tools are for monitoring and analysis. Use them together for best results."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
