{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T11:55:14.210Z",
    "slug": "ck991357-crawl4ai",
    "source_url": "https://github.com/CK991357/gemini-chat/tree/main/src/skills/crawl4ai",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "f288c8973f410a72bec601f4fd83dc2570d3550c8286f4d6e5687764ad2982cf",
    "tree_hash": "c0d84096d2e1aad491f58c745c3024d4ab27d06f6cfe95ef30f5c94e52791342"
  },
  "skill": {
    "name": "crawl4ai",
    "description": "åŠŸèƒ½å¼ºå¤§çš„å¼€æºç½‘é¡µæŠ“å–å’Œæ•°æ®å¤„ç†å·¥å…·ï¼Œæ”¯æŒ6ç§å·¥ä½œæ¨¡å¼ï¼ŒåŒ…æ‹¬æˆªå›¾ã€PDFå¯¼å‡ºå’Œæ™ºèƒ½çˆ¬å–",
    "summary": "åŠŸèƒ½å¼ºå¤§çš„å¼€æºç½‘é¡µæŠ“å–å’Œæ•°æ®å¤„ç†å·¥å…·ï¼Œæ”¯æŒ6ç§å·¥ä½œæ¨¡å¼ï¼ŒåŒ…æ‹¬æˆªå›¾ã€PDFå¯¼å‡ºå’Œæ™ºèƒ½çˆ¬å–",
    "icon": "ğŸ•·ï¸",
    "version": "1.2",
    "author": "CK991357",
    "license": "MIT",
    "category": "web-crawling",
    "tags": [
      "web-scraping",
      "screenshot",
      "pdf-export",
      "structured-data-extraction",
      "deep-crawling",
      "batch-processing",
      "content-extraction",
      "anti-detection",
      "automation"
    ],
    "supported_tools": [
      "claude",
      "codex",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "SKILL.md is pure documentation without executable code. No scripts, network calls, filesystem access, or external commands detected. This is a prompt-based documentation skill describing web scraping API usage.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 1,
    "total_lines": 734,
    "audit_model": "claude",
    "audited_at": "2026-01-10T11:55:14.210Z"
  },
  "content": {
    "user_title": "Scrape websites with Crawl4AI",
    "value_statement": "Extract web content, screenshots, and structured data from any website. Supports intelligent anti-detection crawling with multiple output formats.",
    "seo_keywords": [
      "web scraping",
      "crawl4ai",
      "Claude",
      "Codex",
      "Claude Code",
      "screenshot",
      "PDF export",
      "data extraction",
      "deep crawling",
      "batch processing"
    ],
    "actual_capabilities": [
      "Scrape single web pages with content extraction in markdown, HTML, or text format",
      "Perform deep crawling with keyword filtering and strategy-based navigation",
      "Process multiple URLs in batch with concurrent limiting",
      "Extract structured data using CSS selectors with defined schemas",
      "Capture full-page screenshots and export to PDF with base64 encoding",
      "Automatic anti-detection with browser fingerprint obfuscation"
    ],
    "limitations": [
      "LLM-based extraction mode is not deployed - CSS extraction requires exact selectors",
      "Batch processing limited to 20 pages maximum and 300 seconds overall timeout",
      "External links are excluded by default unless explicitly configured"
    ],
    "use_cases": [
      {
        "target_user": "Researchers",
        "title": "Research Content Collection",
        "description": "Automatically discover and collect relevant content from multiple web sources for analysis."
      },
      {
        "target_user": "Data Analysts",
        "title": "Structured Data Extraction",
        "description": "Extract product information, pricing data, or structured content from websites using CSS selectors."
      },
      {
        "target_user": "Content Creators",
        "title": "Visual Evidence Capture",
        "description": "Capture screenshots and PDF exports of web pages for documentation and archiving."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic Page Scrape",
        "scenario": "Get page content",
        "prompt": "Use crawl4ai to scrape this URL: {url}. Return the content in markdown format."
      },
      {
        "title": "Screenshot Capture",
        "scenario": "Capture visual evidence",
        "prompt": "Use crawl4ai to take a screenshot of {url}. Set quality to 80 and return as base64."
      },
      {
        "title": "Batch Collection",
        "scenario": "Multiple URLs",
        "prompt": "Use crawl4ai batch_crawl mode to process these URLs: {urls}. Use concurrent_limit of 4."
      },
      {
        "title": "Structured Extract",
        "scenario": "Data extraction",
        "prompt": "Use crawl4ai extract mode with CSS selector {selector} to extract: title, author, and publish_date from {url}."
      }
    ],
    "output_examples": [
      {
        "input": "Scrape https://example.com/article about technology",
        "output": [
          "Title: Technology Article Title",
          "Author: John Smith",
          "Published: January 10, 2026",
          "Content: [Full article text in markdown]",
          "Links: 12 internal, 5 external",
          "Images: 3 embedded"
        ]
      }
    ],
    "best_practices": [
      "Always nest parameters inside the 'parameters' object as shown in documentation examples",
      "Use CSS selectors that precisely match page elements for accurate data extraction",
      "Start with scrape mode to test URLs before using deep_crawl or batch modes"
    ],
    "anti_patterns": [
      "Calling crawl4ai without the required mode and parameters wrapper structure",
      "Using extract mode without providing precise CSS selectors",
      "Attempting LLM extraction when only CSS extraction is available"
    ],
    "faq": [
      {
        "question": "What modes does crawl4ai support?",
        "answer": "Six modes: scrape, deep_crawl, batch_crawl, extract, pdf_export, and screenshot."
      },
      {
        "question": "How many URLs can I crawl at once?",
        "answer": "Maximum 20 URLs per batch with 300 second timeout and 4 concurrent limit."
      },
      {
        "question": "Does crawl4ai integrate with other tools?",
        "answer": "Yes, it works with Claude, Codex, and Claude Code through MCP or API calls."
      },
      {
        "question": "Is my data safe when using crawl4ai?",
        "answer": "All data processing happens server-side. No data is stored or forwarded to third parties."
      },
      {
        "question": "Why is my extraction returning empty results?",
        "answer": "Check CSS selectors match actual page elements. LLM extraction is not deployed."
      },
      {
        "question": "How is crawl4ai different from other scrapers?",
        "answer": "Built-in anti-detection, intelligent fallback system, and multi-format output including screenshots and PDF."
      }
    ]
  },
  "file_structure": [
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
