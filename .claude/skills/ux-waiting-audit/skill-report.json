{
  "schema_version": "2.0",
  "meta": {
    "generated_at": "2026-01-10T11:10:41.037Z",
    "slug": "bayramannakov-ux-waiting-audit",
    "source_url": "https://github.com/BayramAnnakov/ux-waiting-audit/tree/main/",
    "source_ref": "main",
    "model": "claude",
    "analysis_version": "2.0.0",
    "source_type": "community",
    "content_hash": "bd872a5597d170a2ceced9a6e32c5c684b7243efefcf88a64cbb3748fd7e6cb1",
    "tree_hash": "07b6ae87b16739104867319258da24852bc61a01720a18424a282938e23b72a6"
  },
  "skill": {
    "name": "ux-waiting-audit",
    "description": "Audit UX waiting states for web applications with long-running operations (30+ seconds). Use when asked to evaluate, audit, or analyze a product's loading states, wait times, progress indicators, or user experience during slow operations. Requires browser automation (Chrome MCP tools). Generates comprehensive reports with screenshots, checklist evaluation, and prioritized recommendations.",
    "summary": "Audit UX waiting states for web applications with long-running operations (30+ seconds). Use when as...",
    "icon": "⏱️",
    "version": "1.0.0",
    "author": "BayramAnnakov",
    "license": "MIT",
    "category": "design",
    "tags": [
      "UX audit",
      "user experience",
      "waiting states",
      "progress indicators",
      "browser automation"
    ],
    "supported_tools": [
      "claude",
      "claude-code"
    ],
    "risk_factors": []
  },
  "security_audit": {
    "risk_level": "safe",
    "is_blocked": false,
    "safe_to_publish": true,
    "summary": "Pure prompt-based skill containing documentation, templates, and JavaScript snippets for browser-based UX evaluation. No network calls, no filesystem access, no external command execution. All JavaScript code is designed for in-browser execution via Chrome MCP tools only.",
    "risk_factor_evidence": [],
    "critical_findings": [],
    "high_findings": [],
    "medium_findings": [],
    "low_findings": [],
    "dangerous_patterns": [],
    "files_scanned": 5,
    "total_lines": 954,
    "audit_model": "claude",
    "audited_at": "2026-01-10T11:10:41.036Z"
  },
  "content": {
    "user_title": "Audit web app waiting states for UX improvements",
    "value_statement": "AI agent products often have long wait times that cause user anxiety and abandonment. This skill audits how applications handle long-running operations using browser automation and generates comprehensive reports with prioritized recommendations.",
    "seo_keywords": [
      "UX waiting states",
      "UX audit",
      "waiting UX",
      "progress indicators",
      "loading states",
      "user experience",
      "AI agent UX",
      "Claude Code",
      "browser automation",
      "UX evaluation"
    ],
    "actual_capabilities": [
      "Navigate to target URLs and trigger long-running operations",
      "Capture screenshots at timed intervals (T+0s, T+10s, T+30s)",
      "Execute DOM queries to detect loading indicators and progress elements",
      "Evaluate against 10-point UX waiting checklist",
      "Generate markdown reports with annotated screenshots",
      "Provide prioritized recommendations for UX improvements"
    ],
    "limitations": [
      "Requires Chrome MCP or similar browser automation tool",
      "Cannot audit native mobile applications",
      "Cannot test operations requiring complex authentication flows without user guidance",
      "Cannot simulate network failures or test graceful degradation automatically"
    ],
    "use_cases": [
      {
        "target_user": "UX designers",
        "title": "Evaluate competitor UX",
        "description": "Audit how competitor products handle long-running AI operations and identify best practices."
      },
      {
        "target_user": "Product managers",
        "title": "Assess own product",
        "description": "Evaluate your application waiting UX and get prioritized improvement recommendations."
      },
      {
        "target_user": "Development teams",
        "title": "Before launch review",
        "description": "Audit new features with long operations before release to catch UX gaps early."
      }
    ],
    "prompt_templates": [
      {
        "title": "Basic audit request",
        "scenario": "Simple audit of a URL",
        "prompt": "Run a UX waiting audit on [URL]. The operation I want you to test is [describe operation] which takes about [X] seconds."
      },
      {
        "title": "Detailed audit with context",
        "scenario": "Full audit with guidance",
        "prompt": "Audit the waiting UX at [URL]. I want you to test [specific operation]. Click the [button name] button to start. Expected duration is [X] seconds. Capture screenshots at T+0, T+10, T+30 and completion."
      },
      {
        "title": "Comparative audit",
        "scenario": "Compare two products",
        "prompt": "Compare waiting UX between [URL1] and [URL2]. Test the [specific operation] on both. Which one handles the wait better and why? Use the 10-point checklist criteria."
      },
      {
        "title": "Before and after review",
        "scenario": "Evaluate improvements",
        "prompt": "Audit the waiting UX at [URL] for the [feature name] operation. Generate a detailed report with screenshots. I will make improvements and then run another audit to compare results."
      }
    ],
    "output_examples": [
      {
        "input": "Audit the waiting UX on our AI research tool when generating a report. The operation takes 45-60 seconds. Click the 'Generate Report' button.",
        "output": [
          "Summary Score: 4/10 categories addressed",
          "Strengths: Shows partial results streaming in, has cancel button",
          "Critical gaps: No time estimation, no progress percentage, spinner only",
          "Quick wins: Add '~50 seconds remaining' text, add progress bar with percentage",
          "P1 Priority: Add time estimation to reduce user anxiety",
          "P2 Priority: Replace spinner with progress bar for visibility",
          "P3 Priority: Add completion celebration animation"
        ]
      }
    ],
    "best_practices": [
      "Always screenshot first before attempting any interaction - visual inspection reveals UI state that DOM queries cannot",
      "Ask users to manually trigger operations when possible to avoid complex navigation and authentication flows",
      "Use the 10-point checklist systematically and provide specific evidence for each scoring decision"
    ],
    "anti_patterns": [
      "Trying multiple selectors when DOM queries fail instead of taking a screenshot to understand the actual UI state",
      "Assuming a spinner alone provides good UX - users need progress indicators, time estimates, and partial results",
      "Auditing without user guidance when complex authentication or specific navigation steps are required"
    ],
    "faq": [
      {
        "question": "Which browsers are supported?",
        "answer": "Chrome MCP is recommended. The skill works with any browser automation tool that provides screenshot, navigate, and execute_javascript capabilities."
      },
      {
        "question": "How long should the tested operation be?",
        "answer": "The skill is designed for operations lasting 30+ seconds. For faster operations, adjust screenshot intervals to T+0, T+50%, and completion."
      },
      {
        "question": "Can I use this without browser automation?",
        "answer": "Partial use is possible. You can use the checklist and report templates manually, but screenshots and DOM state capture require browser automation tools."
      },
      {
        "question": "Is my data safe during the audit?",
        "answer": "Yes. The skill runs entirely in your browser environment through automation tools. No data is sent to external servers by the skill itself."
      },
      {
        "question": "The audit got stuck finding an element. What do I do?",
        "answer": "Stop trying selectors. Take a screenshot immediately and analyze visually. Ask the user for guidance on button location or trigger the operation manually."
      },
      {
        "question": "How is this different from Lighthouse or other auditing tools?",
        "answer": "This skill focuses specifically on waiting UX during long operations. Lighthouse audits performance but not UX patterns like progress indicators, time estimates, or anxiety reduction."
      }
    ]
  },
  "file_structure": [
    {
      "name": "references",
      "type": "dir",
      "path": "references",
      "children": [
        {
          "name": "checklist.md",
          "type": "file",
          "path": "references/checklist.md"
        },
        {
          "name": "report-template.md",
          "type": "file",
          "path": "references/report-template.md"
        }
      ]
    },
    {
      "name": "scripts",
      "type": "dir",
      "path": "scripts",
      "children": [
        {
          "name": "capture_state.js",
          "type": "file",
          "path": "scripts/capture_state.js"
        }
      ]
    },
    {
      "name": "README.md",
      "type": "file",
      "path": "README.md"
    },
    {
      "name": "SKILL.md",
      "type": "file",
      "path": "SKILL.md"
    }
  ]
}
